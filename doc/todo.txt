내가 원하는 것:
     커맨드를 다르게 넣으면 다른 실험을 할 수 있음.
     실험은 스크립트 파일 하나로 정의됨. -> 실험마다 다른 Experiment를 만들어야 함.
     모든 설정과 결과는 DB에 저장되고 차후에 비교 가능.
     CLI가 있고 expr이 있음. expr에 실험 스크립트를 저장함.
     Experiment의 이름은 기본적으로는 실험 스크립트와 같도록..
     
     큰 실험이 있고, 거기서 옵션만 좀 바뀌는 건 CLI로 처리 가능..
학습에서 달라지는 것(독립변수):
데이터셋
학습 방법
모델

커맨드 - 태스크

학습 파이프라인
데이터셋 전처리 -> 학습 -> (완료) -> 평가
평가방법

tasks   설정한 (실험) 스크립트들
expr    실험 관련 재사용 함수
  common
  config
  ..
data    데이터 관련 함수
utils   유틸리티 함수
nn      모델, loss 등 뉴럴넷 관련 함수

sacred로 할 일:
간편한 CLI 설정
모든 실험 결과 저장

easy_only로 할 일:
결과가 좋은 모델 찾기(평가하기)
manga109의 글자를 지우고 데이터셋 생성하기.

--------------------------------------------------------

20일까지 할 일
- 데이터는 기존 그대로(split 맞추기) 쓰기
- train/valid/test 데이터 로드하고 학습하기
- 학습 중에 tensorboard로 이미지 확인하기
- 여러 모델 학습시켜서 돌리기
- pretrained network 사용하기
- 통일된 성능 측정

-> 논문에 쓸 내용 만들기
- 다양한 모델의 성능 평가 및 내 해석
    - 어떤 특징을 가진 모델이 성능이 잘 나오는지 파악할 것
- 데이터에 대한 것

------------------------------------------------

다양한 데이터셋 대응 가능
    bioseg
    manga

데이터셋 요구사항 검증
    정해진 색 외에 다른 색(cmap 참조)은 없나?
    개수는 같은가?
    look-and-feel 체크
    ...

학습
    tf2 이용

모델
    amazing semantic segmentation 사용
    내가 구성한 모델도 사용

테스트
    hypothesis (generative test) 사용

------------------------------------------------
로깅, 메타데이터 관리는 sacred를 이용함.

LICENSE
README.md
requirements.txt

doc
    todo.txt

nnlab
    main.py         엔트리 포인트, 태스크 설정[현재 test_dset 생성]

    util        재활용 가능 코드
        fp.py
        file_util.py
        image_util.py

    data        데이터 관련 코드
        io.py       데이터 io [old snet data dset_dict -> namedtuple]
        image.py    이미지 관련(img -> tfrecord..)

    expr        실험 관련 코드
        train.py    학습 루프 [empty]
        test.py     학습 이후 성능 평가 등

    nn          뉴럴넷 구성 코드
        model.py    모델 설정
        loss.py     [empty]
        metric.py   [empty]
        
    tasks
        dataset.py  [tfrecord dataset 생성]

test
    utils
        fp_test.py
        file_util_test.py
        image_util_test.py

    data      
        io_test.py 
        data_test.py 

    expr
        train_test.py
        test_test.py 

    nn
        model_test.py
        loss_test.py
        metric_test.py
